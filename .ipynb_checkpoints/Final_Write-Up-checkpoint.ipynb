{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de495c7e",
   "metadata": {},
   "source": [
    "# CSE151A_UrbanAnimals\n",
    "#### Unveiling patterns: predictive modeling of animal disposition in urban settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340e190",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca9376",
   "metadata": {},
   "source": [
    "With the increasing volume of animals picked up by urban animal control centers, understanding and predicting the outcomes of these incidents have become crucial for effective management and resource allocation. In this study, we leverage a comprehensive 7-year dataset from Baton Rouge Animal Control and Rescue Center (ACRC) to develop a supervised machine learning model that predicts the disposition of animals based on a variety of characteristics such as incident date, request type, location, species, breed, sex, size, age, condition, etc. \n",
    "\n",
    "Our goal is to, with the help of this dataset, be able to predict the behaviour of each animal species depending on the time of the year and other factors such as location, to subsequently predict how many animal controllers should be attending each call and possibly help them decide the tools to use and how to perfomr in each task. This supervised predictive model can aid in prioritizing resources, optimizing intervention strategies, and ultimately improving the welfare of animals within urban communities.\n",
    "\n",
    "The results of our study will not only contribute to a deeper understanding of the factors influencing animal outcomes but will also provide a practical tool for other animal control centers to anticipate the disposition of animals in their care. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4323c3",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77dfaf",
   "metadata": {},
   "source": [
    "__Delete cell prior to turnin:__ ------------------------------------------\n",
    "_Include figures (of your choosing to help with the narration of your story) with legends (similar to a scientific paper) For reference you search machine learning and your model in google scholar for reference examples._\n",
    "\n",
    "_Methods section (this section will include the exploration results, preprocessing steps, models chosen in the order they were executed. Parameters chosen. Please make sub-sections for every step. i.e Data Exploration, Preprocessing, Model 1, Model 2, Model 3, (note models can be the same i.e. CNN but different versions of it if they are distinct enough). You can put links here to notebooks and/or code blocks using three ' in markup for displaying code. so it would look like this: ''' MY CODE BLOCK '''_\n",
    "\n",
    "_Note: A methods section does not include any why. the reason why will be in the discussion section. This is just a summary of your methods_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea72ea",
   "metadata": {},
   "source": [
    "#### 1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31aa7e2",
   "metadata": {},
   "source": [
    "For data exploration, we looked at missing value counts for each column, Male:Female ratios for each species, condition distributions for each species, and a pairplot and heatmap for each category. After identifying the features of interest and areas of concern such as missing values, we began the preprocessing for the data.\n",
    "\n",
    "Here's the link to the related data exploration notebooks: \n",
    "- https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/notebook.ipynb\n",
    "- https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/Untitled.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3f4b8",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd3fc7",
   "metadata": {},
   "source": [
    "To begin, our team identified the large amounts of missing values in the data. The columns of concern were primarily age, sex, and request type. We immediately decided to drop zip_code and request type, as we have complete data in latitude and longitude to determine location of each entry and request type is largely unrelated to our project. As the remaining counts of missing values represented a small portion of our data, we agreed to drop all rows with unknown values except for those in the column of sex, with unknown denoted as \"U\". After cleaning up the unknown values, we then proceeded to correct typos and consolidate different spellings or naming conventions referring to one specific breed of a species, such as \"Pitbull\", \"Pit Bull\", and \"Pit\". Since our data largely consisted of dogs, we also decided to categorize every breed into several groups to simplify our data and prevent runtime issues when training models. Similarly, we then grouped the date-time values and remapped them to the four seasons. After consolidating and simplifying, the categorical features were then one-hot encoded, followed by a [0,1] min max scaling across the numerical features. \n",
    "\n",
    "Here's the link to the preprocessing notebook: \n",
    "- https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33116cc9",
   "metadata": {},
   "source": [
    "#### 3. Our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c052c2",
   "metadata": {},
   "source": [
    "_In this project..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b3df9",
   "metadata": {},
   "source": [
    "##### 3.a) Model 1: Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbaf611",
   "metadata": {},
   "source": [
    "We have started to work separately into different groups, each developing a different first mode simultaneaously: decision tree, logistical regression, perceptron and SVM.\n",
    "\n",
    "After getting to some promising conclussions in decission trees, logistic regression and perceptrons, we decided the first model we are presenting is the perceptron. \n",
    "\n",
    "Our model consisted of 7 hidden layers: a pair of 96 node layers, a pair of 48 node layers, a pair of 16 node layers, and a final 5 node layer with a sigmoid function. Each pair has one layer with a relu activation function and another layer with a tanh function. We used stochastic gradient descent with a learning rate of 0.01 as our optimizer. In total, we trained the model for 200 epochs using a batch size of 150 and a validation split size of 0.1. We used MSE as our loss function.\n",
    "\n",
    "Here is the link to the perceptron notebook: https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/perceptron.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271b832",
   "metadata": {},
   "source": [
    "##### 3.b) Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d3829",
   "metadata": {},
   "source": [
    "On this second turn-in, we're leaning towards going with logistic regression. We dived into a binary approach for this model. More on the following sections.\n",
    "\n",
    "Here is the link to the logistic regression notebook: https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/logistical_regres.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a21c0f",
   "metadata": {},
   "source": [
    "##### 3.c) Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6f634",
   "metadata": {},
   "source": [
    "Finally, we decided to lean towards a decision tree model. We decided to try simple decision tree, and then we tried to oversample our model. After getting better results than expected, we also tried random forest and finally ensambles. More about our  process in the next sections.\n",
    "\n",
    "Here is the link to our decision tree notebook: https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/decisiontree_notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02646df6",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9b2df",
   "metadata": {},
   "source": [
    "__Delete cell prior to turnin:__ ------------------------------------------\n",
    "_This will include the results from the methods listed above (Methods). You will have figures here about your results as well._\n",
    "\n",
    "_No exploration of results is done here. This is mainly just a summary of your results. The sub-sections will be the same as the sections in your methods section._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f8b18",
   "metadata": {},
   "source": [
    "#### 1. Model 1: Perceptron Results/Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ec301",
   "metadata": {},
   "source": [
    "<img src=\"graph_perceptron.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "<img src=\"graph_perceptron_loss.png\" width=\"650\" height=\"650\" />\n",
    "\n",
    "Our final test and train accuracy and loss values were as follows:\n",
    "\n",
    "```\n",
    "Test loss: 0.11528602242469788\n",
    "Test accuracy: 0.5306574106216431\n",
    "\n",
    "Train loss: 0.11475052684545517\n",
    "Train accuracy: 0.5378226637840271\n",
    "```\n",
    "\n",
    "The following confusion matrix is based on our model's predictions on the test data set.\n",
    "![cm](cm_perceptron.png)\n",
    "\n",
    "Finally, our classification report based on the same data used in the confusion matrix:\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "      NORMAL       0.75      0.55      0.63      3337\n",
    "    FRIENDLY       0.42      0.92      0.58      2194\n",
    "     NERVOUS       0.00      0.00      0.00      1504\n",
    "   DANGEROUS       0.00      0.00      0.00       185\n",
    "      SCARED       0.00      0.00      0.00         5\n",
    "\n",
    "   micro avg       0.53      0.53      0.53      7225\n",
    "   macro avg       0.23      0.29      0.24      7225\n",
    "weighted avg       0.47      0.53      0.47      7225\n",
    " samples avg       0.53      0.53      0.53      7225\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c2431",
   "metadata": {},
   "source": [
    "#### 2. Model 2: Logistic Regression Results/Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7421d9cf",
   "metadata": {},
   "source": [
    "_In this project..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9f369",
   "metadata": {},
   "source": [
    "#### 3. Model 3: Decision Tree Results/Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44423a7",
   "metadata": {},
   "source": [
    "Fitting Graph:\n",
    "\n",
    "![fitting](dtree_oversample.png)\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.95      0.87      5024\n",
    "           1       0.94      0.79      0.86      5515\n",
    "\n",
    "    accuracy                           0.87     10539\n",
    "    macro avg       0.87      0.87     0.87     10539\n",
    "    weighted avg    0.88      0.87     0.87     10539\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "![cm](dtree_cm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3175d",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb178b",
   "metadata": {},
   "source": [
    "__Delete cell prior to turnin: ------------------------------------------__\n",
    "_This is where you will discuss the why, and your interpretation and your though process from beginning to end. This will mimic the sections you have created in your methods section as well as new sections you feel you need to create. You can also discuss how believable your results are at each step. You can discuss any short comings. It's ok to criticize as this shows your intellectual merit, as to how you are thinking about things scientifically and how you are able to correctly scrutinize things and find short comings. In science we never really find the perfect solution, especially since we know something will probably come up int he future (i.e. donkeys) and mess everything up. If you do it's probably a unicorn or the data and model you chose are just perfect for each other!_\n",
    "\n",
    "_Your final model (model 3) and final results summary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccbf78",
   "metadata": {},
   "source": [
    "In this section we will be discussing the why, and our interpretation of the process. We will also talk about our results, and whether they could be improved within each model or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a6ba6",
   "metadata": {},
   "source": [
    "##### a) Model 1: Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f160f",
   "metadata": {},
   "source": [
    "Like we said earlier on, after getting to some promising conclussions in decission trees, logistic regression and perceptrons, we decided the first model we were presenting is the perceptron. \n",
    "\n",
    "This is because both train and test accuracies present similar proper results. The test and train accuracies are about 0.5319 and 0.5371, respectively. We are getting a higher rate of accuracy than expected on the model, making results convincing at the end. However, the loss graph shows that by the end of our training, we were starting to overfit as our training loss was still slowly decreasing while our testing loss had started to plateau and bounce up and down after around epoch 115.\n",
    "\n",
    "Based on the confusion matrix and classification report, we can see that our model was not good at precision or recall of 'NERVOUS', 'DANGEROUS', or 'SCARED' temperaments. The 'SCARED' class in particular is probably suffering from underrepresentation because of how few samples there are in the entire data set, however the results for 'NERVOUS' and 'DANGEROUS' indicate that there are other issues with the model that make it unable to predict these classes. This was most likely due to the activation function for the output layer being a sigmoid function which should be used for binary classification. Our problem on the otherhand is a multiclass classification problem.\n",
    "\n",
    "If we were to improve the model, we could definitely try different activation functions, using a different learning rate, adjusting the number of nodes per layer, and adjusting the number of layers in total. This would be done with hyperparameter tuning to find the best parameters given the large number of different possible combinations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a9f1f",
   "metadata": {},
   "source": [
    "##### b) Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714ba17",
   "metadata": {},
   "source": [
    "Like we mentioned earlier on this file, we tried different models when we first started our project, and eventhough our logistic regression achieved better initial performance than our decision tree, we feel like this first one has less options for hyperparameter tuning.\n",
    "\n",
    "Therefore, we are picking logistic regression because we think that with more time in our hands, we'll be able to dive deeper into tuning the decision tree to get a final better result on our project. This is the model we are going to be tackling next. We're hoping to get better results next time.\n",
    "\n",
    "We haven't done any parameter tuning, feature extension or K-fold cross validation in our model, which might explain why the accuracy value was not too high. We might have taken into consideration one of the previous methods to improve our model's accuracy.\n",
    "\n",
    "__Here would go a picture of comparison between training vs test error (sorry idk how to do it)__ -------------------------\n",
    "_And we would have to answer these questions: \n",
    "Where does your model fit in the fitting graph, how does it compare to your first model?\n",
    "How did this model perform comparing to your first and why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af401f66",
   "metadata": {},
   "source": [
    "##### c) Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617f028",
   "metadata": {},
   "source": [
    "Our exploration began with a Decision Tree Classifier trained to predict animal outcomes based on various incident characteristics. We targeted two main classes by aggregating 'NORMAL' and 'FRIENDLY' into one class and considering 'NERVOUS', 'DANGEROUS', and 'SCARED' as another class. This simplification was necessitated by the challenges in distinguishing between the more nuanced classes (especially those with fewer samples, see explanation for perceptron above), and it led to an improvement in our model's accuracy.\n",
    "\n",
    "A challenge we faced was the model's tendency to overfit, as evidenced by the initial difference between the training (98.83%) and test (72.02%) accuracies. With our initial model, the difference between the two were 27%. To combat this, we implemented oversampling, which not only reduced overfitting but also enhanced the model's test accuracy.\n",
    "\n",
    "The classification report shows our model's strength in precisely identifying the 'sensitive' cases (class 0) while maintaining a high recall, thereby minimizing the risk of overlooking such critical instances. The balance in the f1-score across both classes confirms that our decision to implement oversampling effectively countered the initial class imbalance.\n",
    "\n",
    "Further experiments were conducted with RandomForest, AdaBoost, and GradientBoosting classifiers. For RandomForest, we found only a negligible increase in accuracy compared to the baseline Decision Tree model. The other experiments did not yield satisfactory results and were not used.\n",
    "\n",
    "Of course, further improvements could be made via hyperparameter tuning for our DecisionTree model, alongside possible further testing for RandomForest as it too showed similar potential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea0574",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6615bf",
   "metadata": {},
   "source": [
    "__Delete cell prior to turnin:__ ------------------------------------------\n",
    "_This is where you do a mind dump on your opinions and possible future directions. Basically what you wish you could have done differently. Here you close with final thoughts_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118cd36",
   "metadata": {},
   "source": [
    "## Collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835e4c9",
   "metadata": {},
   "source": [
    "__Delete cell prior to turnin:__ ------------------------------------------\n",
    "_This is a statement of contribution by each member. This will be taken into consideration when making the final grade for each member in the group. Did you work as a team? was there a team leader? project manager? coding? writer? etc. Please be truthful about this as this will determine individual grades in participation. There is no job that is better than the other. If you did no code but did the entire write up and gave feedback during the steps and collaborated then you would still get full credit. If you only coded but gave feedback on the write up and other things, then you still get full credit. If you managed everyone and the deadlines and setup meetings and communicated with teaching staff only then you get full credit. Every role is important as long as you collaborated and were integral to the completion of the project. If the person did nothing. they risk getting a big fat 0. Just like in any job, if you did nothing, you have the risk of getting fired. Teamwork is one of the most important qualities in industry and academia!!!_\n",
    "\n",
    "_Start with Name: Title: Contribution. If the person contributed nothing then just put in writing: Did not participate in the project._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f4174",
   "metadata": {},
   "source": [
    "In this group project, we've been working together the following way:\n",
    " - Name: Title: Contribution\n",
    " - Paula Esteban Carrillo: Title: assumed a central role in facilitating effective organization and coordination within our group project. Additionally,  collaborated with other team members in drafting several sections of the project documentation, as well as discussing feedback on each step of the process.\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb69a02",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
