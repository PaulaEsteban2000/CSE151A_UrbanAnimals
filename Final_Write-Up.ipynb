{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de495c7e",
   "metadata": {
    "id": "de495c7e"
   },
   "source": [
    "# CSE151A_UrbanAnimals\n",
    "#### Unveiling patterns: predictive modeling of animal disposition in urban settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340e190",
   "metadata": {
    "id": "2340e190"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca9376",
   "metadata": {
    "id": "91ca9376"
   },
   "source": [
    "With the increasing volume of animals picked up by urban animal control centers, understanding and predicting the outcomes of these incidents have become crucial for effective management and resource allocation. In this study, we leverage a comprehensive 7-year dataset from Baton Rouge Animal Control and Rescue Center (ACRC) to develop a supervised machine learning model that predicts the disposition of animals based on a variety of characteristics such as incident date, request type, location, species, breed, sex, size, age, condition, etc.\n",
    "\n",
    "Our goal is to, with the help of this dataset, be able to predict the behaviour of each animal species depending on the time of the year and other factors such as location, to subsequently predict how many animal controllers should be attending each call and possibly help them decide the tools to use and how to perform in each task. This supervised predictive model can aid in prioritizing resources, optimizing intervention strategies, and ultimately improving the welfare of animals within urban communities.\n",
    "\n",
    "The results of our study will not only contribute to a deeper understanding of the factors influencing animal outcomes but will also provide a practical tool for other animal control centers to anticipate the disposition of animals in their care."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4323c3",
   "metadata": {
    "id": "bb4323c3"
   },
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea72ea",
   "metadata": {
    "id": "4dea72ea"
   },
   "source": [
    "#### 1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31aa7e2",
   "metadata": {
    "id": "a31aa7e2"
   },
   "source": [
    "For data exploration, we looked at missing value counts for each column, Male:Female ratios for each species, condition distributions for each species, and a pairplot and heatmap for each category. After identifying the features of interest and areas of concern such as missing values, we began the preprocessing for the data.\n",
    "\n",
    "Here's the link to the related data exploration notebooks:\n",
    "- https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/notebook.ipynb\n",
    "- https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/Untitled.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3f4b8",
   "metadata": {
    "id": "0cf3f4b8"
   },
   "source": [
    "#### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd3fc7",
   "metadata": {
    "id": "88dd3fc7"
   },
   "source": [
    "To begin, our team identified the large amounts of missing values in the data. The columns of concern were primarily age, sex, and request type. We immediately decided to drop zip_code and request type, as we have complete data in latitude and longitude to determine location of each entry and request type is largely unrelated to our project. As the remaining counts of missing values represented a small portion of our data, we agreed to drop all rows with unknown values except for those in the column of sex, with unknown denoted as \"U\". After cleaning up the unknown values, we then proceeded to correct typos and consolidate different spellings or naming conventions referring to one specific breed of a species, such as \"Pitbull\", \"Pit Bull\", and \"Pit\". Since our data largely consisted of dogs, we also decided to categorize every breed into several groups to simplify our data and prevent runtime issues when training models. Similarly, we then grouped the date-time values and remapped them to the four seasons. After consolidating and simplifying, the categorical features were then one-hot encoded, followed by a [0,1] min max scaling across the numerical features.\n",
    "\n",
    "Here's the link to the preprocessing notebook:\n",
    "- https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33116cc9",
   "metadata": {
    "id": "33116cc9"
   },
   "source": [
    "#### 3. Our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b3df9",
   "metadata": {
    "id": "937b3df9"
   },
   "source": [
    "##### 3.a) Model 1: Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbaf611",
   "metadata": {
    "id": "bfbaf611"
   },
   "source": [
    "We have started to work separately into different groups, each developing a different first mode simultaneaously: decision tree, logistical regression, perceptron and SVM.\n",
    "\n",
    "After getting to some promising conclussions in decission trees, logistic regression and perceptrons, we decided the first model we are presenting is the perceptron.\n",
    "\n",
    "Our model consisted of 7 hidden layers: a pair of 96 node layers, a pair of 48 node layers, a pair of 16 node layers, and a final 5 node layer with a sigmoid function. Each pair has one layer with a relu activation function and another layer with a tanh function. We used stochastic gradient descent with a learning rate of 0.01 as our optimizer. In total, we trained the model for 200 epochs using a batch size of 150 and a validation split size of 0.1. We used MSE as our loss function.\n",
    "\n",
    "Here is the link to the perceptron notebook: https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/perceptron.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271b832",
   "metadata": {
    "id": "1271b832"
   },
   "source": [
    "##### 3.b) Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d3829",
   "metadata": {
    "id": "4d2d3829"
   },
   "source": [
    "On this second turn-in, we're leaning towards going with logistic regression. We dived into a binary approach for this model. More on the following sections.\n",
    "\n",
    "Here is the link to the logistic regression notebook: https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/logistical_regres_final.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a21c0f",
   "metadata": {
    "id": "48a21c0f"
   },
   "source": [
    "##### 3.c) Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6f634",
   "metadata": {
    "id": "2fa6f634"
   },
   "source": [
    "Finally, we decided to lean towards a decision tree model. We decided to try simple decision tree, and then we tried to oversample our model. After getting better results than expected, we also tried random forest and finally ensambles. More about our  process in the next sections.\n",
    "\n",
    "Here is the link to our decision tree notebook: https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/decisiontree_notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02646df6",
   "metadata": {
    "id": "02646df6"
   },
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f8b18",
   "metadata": {
    "id": "3f5f8b18"
   },
   "source": [
    "#### 1. Model 1: Perceptron Results/Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ec301",
   "metadata": {
    "id": "519ec301"
   },
   "source": [
    "<img src=\"https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/graph_perceptron.png?raw=1\" width=\"600\" height=\"600\" />\n",
    "\n",
    "<img src=\"https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/graph_perceptron_loss.png?raw=1\" width=\"650\" height=\"650\" />\n",
    "\n",
    "Our final test and train accuracy and loss values were as follows:\n",
    "\n",
    "```\n",
    "Test loss: 0.11528602242469788\n",
    "Test accuracy: 0.5306574106216431\n",
    "\n",
    "Train loss: 0.11475052684545517\n",
    "Train accuracy: 0.5378226637840271\n",
    "```\n",
    "\n",
    "The following confusion matrix is based on our model's predictions on the test data set.\n",
    "![cm](https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/cm_perceptron.png?raw=1)\n",
    "\n",
    "Finally, our classification report based on the same data used in the confusion matrix:\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "      NORMAL       0.75      0.55      0.63      3337\n",
    "    FRIENDLY       0.42      0.92      0.58      2194\n",
    "     NERVOUS       0.00      0.00      0.00      1504\n",
    "   DANGEROUS       0.00      0.00      0.00       185\n",
    "      SCARED       0.00      0.00      0.00         5\n",
    "\n",
    "   micro avg       0.53      0.53      0.53      7225\n",
    "   macro avg       0.23      0.29      0.24      7225\n",
    "weighted avg       0.47      0.53      0.47      7225\n",
    " samples avg       0.53      0.53      0.53      7225\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c2431",
   "metadata": {
    "id": "204c2431"
   },
   "source": [
    "#### 2. Model 2: Logistic Regression Results/Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o5esUxEdy5Qt",
   "metadata": {
    "id": "o5esUxEdy5Qt"
   },
   "source": [
    "![cm](https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/lr.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G19py_CyxU9b",
   "metadata": {
    "id": "G19py_CyxU9b"
   },
   "source": [
    "Before Binary Classification\n",
    "\n",
    "```\n",
    "Classification Report:  precision  recall   f1-score  support\n",
    "\n",
    "                 0       0.85      0.97      0.91     28900\n",
    "                 1       0.73      0.31      0.43     7225\n",
    "\n",
    "    accuracy                           0.84     36125\n",
    "   macro avg       0.79      0.64      0.67     36125\n",
    "weighted avg       0.82      0.84      0.81     36125\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6l5sJpT3x0kT",
   "metadata": {
    "id": "6l5sJpT3x0kT"
   },
   "source": [
    "After Binary classification.\n",
    "\n",
    "```\n",
    "Train Accuracy: 0.7788895040734003\n",
    "Test Accuracy: 0.7810279597674633\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y_YBBYZYx_99",
   "metadata": {
    "id": "Y_YBBYZYx_99"
   },
   "source": [
    "# After Tuning\n",
    "Tuning with Class weight\n",
    "\n",
    "```\n",
    "Train Accuracy: 0.5945582535790556\n",
    "Test Accuracy: 0.5913075574420965\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aMqtqF12zt09",
   "metadata": {
    "id": "aMqtqF12zt09"
   },
   "source": [
    "Our final results we did tuning with different intercepts, resulting in the graph above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lbV2SA2QzYMy",
   "metadata": {
    "id": "lbV2SA2QzYMy"
   },
   "source": [
    "```\n",
    "Train Accuracy: 0.7788895040734003\n",
    "Test Accuracy: 0.7810279597674633\n",
    "---\n",
    "Train Accuracy: 0.778929051649134\n",
    "Test Accuracy: 0.7807511303866383\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SSfmHufnyQMG",
   "metadata": {
    "id": "SSfmHufnyQMG"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7de9f369",
   "metadata": {
    "id": "7de9f369"
   },
   "source": [
    "#### 3. Model 3: Decision Tree Results/Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44423a7",
   "metadata": {
    "id": "d44423a7"
   },
   "source": [
    "Fitting Graph:\n",
    "\n",
    "![fitting](https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/dtree_oversample.png?raw=1)\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.95      0.87      5024\n",
    "           1       0.94      0.79      0.86      5515\n",
    "\n",
    "    accuracy                           0.87     10539\n",
    "    macro avg       0.87      0.87     0.87     10539\n",
    "    weighted avg    0.88      0.87     0.87     10539\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "![cm](https://github.com/PaulaEsteban2000/CSE151A_UrbanAnimals/blob/main/dtree_cm.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3175d",
   "metadata": {
    "id": "b8f3175d"
   },
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccbf78",
   "metadata": {
    "id": "83ccbf78"
   },
   "source": [
    "In this section we will be discussing the why, and our interpretation of the process. We will also talk about our results, and whether they could be improved within each model or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a6ba6",
   "metadata": {
    "id": "672a6ba6"
   },
   "source": [
    "##### a) Model 1: Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f160f",
   "metadata": {
    "id": "2b4f160f"
   },
   "source": [
    "Like we said earlier on, after getting to some promising conclussions in decission trees, logistic regression and perceptrons, we decided the first model we were presenting is the perceptron.\n",
    "\n",
    "This is because both train and test accuracies present similar proper results. The test and train accuracies are about 0.5319 and 0.5371, respectively. We are getting a higher rate of accuracy than expected on the model, making results convincing at the end. However, the loss graph shows that by the end of our training, we were starting to overfit as our training loss was still slowly decreasing while our testing loss had started to plateau and bounce up and down after around epoch 115.\n",
    "\n",
    "Based on the confusion matrix and classification report, we can see that our model was not good at precision or recall of 'NERVOUS', 'DANGEROUS', or 'SCARED' temperaments. The 'SCARED' class in particular is probably suffering from underrepresentation because of how few samples there are in the entire data set, however the results for 'NERVOUS' and 'DANGEROUS' indicate that there are other issues with the model that make it unable to predict these classes. This was most likely due to the activation function for the output layer being a sigmoid function which should be used for binary classification. Our problem on the otherhand is a multiclass classification problem.\n",
    "\n",
    "If we were to improve the model, we could definitely try different activation functions, using a different learning rate, adjusting the number of nodes per layer, and adjusting the number of layers in total. This would be done with hyperparameter tuning to find the best parameters given the large number of different possible combinations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a9f1f",
   "metadata": {
    "id": "624a9f1f"
   },
   "source": [
    "##### b) Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714ba17",
   "metadata": {
    "id": "2714ba17"
   },
   "source": [
    "After running our first model we decided to explore data analysis with logistical regression. After doing our logistical regression, our first classification report we received 84% accuracy. The initial results seemed promising so we delved deeper trying to enhance the performance and seeing if we could get better results by attempting binary classification, and hyperparameter tuning.\n",
    "\n",
    "After using binary classification our results dropped to 78%. We continued to try a different approach, hyperparameter tuning with class weights. After running it, we saw a decrease in model performance, resulting in 59% accuracy.The resulting decrease may have been from non optimal hyperparameters.\n",
    "\n",
    "We then decided to use different intercept settings in our model which resulted in 78% test accuracy. The results were much better than class weight but still a decrease in performance.\n",
    "\n",
    "Logistical regression seemed promising, however our attempts to use different tuning methods and classifications did not increase the performance. In hindsight, we may have been able to achieve better model performance had we done various experimentation with other classifications or hyperparameters. However, after our failed attempts to get better results, we believed it best to begin exploring with a decision tree model instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af401f66",
   "metadata": {
    "id": "af401f66"
   },
   "source": [
    "##### c) Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617f028",
   "metadata": {
    "id": "7617f028"
   },
   "source": [
    "Our exploration began with a Decision Tree Classifier trained to predict animal outcomes based on various incident characteristics. We targeted two main classes by aggregating 'NORMAL' and 'FRIENDLY' into one class and considering 'NERVOUS', 'DANGEROUS', and 'SCARED' as another class. This simplification was necessitated by the challenges in distinguishing between the more nuanced classes (especially those with fewer samples, see explanation for perceptron above), and it led to an improvement in our model's accuracy.\n",
    "\n",
    "A challenge we faced was the model's tendency to overfit, as evidenced by the initial difference between the training (98.83%) and test (72.02%) accuracies. With our initial model, the difference between the two were 27%. To combat this, we implemented oversampling, which not only reduced overfitting but also enhanced the model's test accuracy.\n",
    "\n",
    "The classification report shows our model's strength in precisely identifying the 'sensitive' cases (class 0) while maintaining a high recall, thereby minimizing the risk of overlooking such critical instances. The balance in the f1-score across both classes confirms that our decision to implement oversampling effectively countered the initial class imbalance.\n",
    "\n",
    "Further experiments were conducted with RandomForest, AdaBoost, and GradientBoosting classifiers. For RandomForest, we found only a negligible increase in accuracy compared to the baseline Decision Tree model. The other experiments did not yield satisfactory results and were not used.\n",
    "\n",
    "Of course, further improvements could be made via hyperparameter tuning for our DecisionTree model, alongside possible further testing for RandomForest as it too showed similar potential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea0574",
   "metadata": {
    "id": "b4ea0574"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757083a",
   "metadata": {
    "id": "b757083a"
   },
   "source": [
    "Our project aimed to develop a predictive model to help better understand and anticipate animal disposition in urban settings using data sourced from Baton Rouge Animal Control and Rescue Center. Through data exploration, preprocessing, and development and analysis of a supervised machine learning model, we have gained better insight into the factors that are more likely to influence animal behavior, as well as uncovering the strengths and weaknesses of the three models that we decided to use.\n",
    "\n",
    "The Decision Tree Classifier proved to be the model that we were able to achieve the best results, though out of necessity, we had to group our five classifications of animal behavior into “sensitive” (NORMAL or FRIENDLY) cases and “non-sensitive” (NERVOUS, DANGEROUS, or SCARED) cases, as well as implement oversampling techniques. This model was able to identify “sensitive” cases accurately and maintain a high recall rate. This model was further experimented upon by implementing other classifiers in hopes of increasing accuracy, however these results showed little difference in accuracy compared to the baseline model. If given more time for improvement, improving hyperparameter tuning and experimenting more with the RandomForest classifier might give more accurate results.\n",
    "\n",
    "Our other models certainly had room for improvement. The Perception model suffered from having trouble accurately predicting results from the ‘NERVOUS’ and ‘DANGEROUS’ classes. While it achieved a reasonable test and train accuracy, it had trouble with overfitting and our testing and training losses after epoch 115. To improve upon this model, we could have experimented with different activation functions as well as improving hyperparameter tuning, as the activation function seemed to be a root cause of the results we got. Additionally using a different learning rate, a different number of nodes per layer, and changing the number of layers could have given us better results too.\n",
    "\n",
    "Lastly, our Logistic Regression model achieved better performance but at the cost of less hyperparameter tuning options. To further develop this model, implementing more hyperparameter tuning, feature extension or K-fold cross validation would be implemented in hopes of improving its accuracy.\n",
    "\n",
    "All things considered, our project achieved its goal in finding valuable insights into the factors affecting animal behavior in urban settings, which can be applied as a tool for animal control centers to improve upon their resource allocation and intervention strategies, which ultimately benefit communities as well as the animals themselves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118cd36",
   "metadata": {
    "id": "b118cd36"
   },
   "source": [
    "## Collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835e4c9",
   "metadata": {
    "id": "2835e4c9"
   },
   "source": [
    "__Delete cell prior to turnin:__ ------------------------------------------\n",
    "_This is a statement of contribution by each member. This will be taken into consideration when making the final grade for each member in the group. Did you work as a team? was there a team leader? project manager? coding? writer? etc. Please be truthful about this as this will determine individual grades in participation. There is no job that is better than the other. If you did no code but did the entire write up and gave feedback during the steps and collaborated then you would still get full credit. If you only coded but gave feedback on the write up and other things, then you still get full credit. If you managed everyone and the deadlines and setup meetings and communicated with teaching staff only then you get full credit. Every role is important as long as you collaborated and were integral to the completion of the project. If the person did nothing. they risk getting a big fat 0. Just like in any job, if you did nothing, you have the risk of getting fired. Teamwork is one of the most important qualities in industry and academia!!!_\n",
    "\n",
    "_Start with Name: Title: Contribution. If the person contributed nothing then just put in writing: Did not participate in the project._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f4174",
   "metadata": {
    "id": "2d5f4174"
   },
   "source": [
    "In this group project, we've been working together the following way:\n",
    " - Name: Title: Contribution\n",
    " - Paula Esteban Carrillo: Project manager/Writer: Assumed a central role in facilitating effective organization and coordination within our group project. Additionally,  collaborated with other team members in drafting most sections of the project documentation, as well as discussing feedback on each step of the project process. Been active on group chat and attended all meetings.\n",
    " - Nick Ehsani: Writer. Worked on the writeup and analyzed results from the models and helped make decisions concerning what factors were worth cutting from the dataset, and how to organize and manage these factors.\n",
    " - Thomas Limperis: Data analyst: Performed various data exploration with logistical regression, neural networks. Worked with team members to discuss best approaches and or problems we faced. Showed up to most team meetings and active in our group chat, made sure our files were ready for final submissions.\n",
    " - Kevin Liu: Data analyst: Helped with data exploration to change the dataset into a usable state. Additionally worked on the perceptron model and worked with teammates to decide our overall plan.\n",
    " - Arjun Suresh Kumar: Data analyst: Performed initial data exploration tasks and contributed heavily to data preprocessing tasks. Helped perform model exploration by preliminary testing of different model types. Worked with team members to discuss workload/model assignment. Contributed to finalization of decision tree notebook and logistic regression\n",
    " - Rohan Meserve: Coder/Data analyst: Contributed heavily to EDA, logistic regression notebook, and decision tree notebook. Made minor contributions to preprocessing. Participated in discussions on project adjustments / improvements (such as swapping to a binary task and implementing oversampling), as well as their implementation. Actively communicated in team group chat, and had regular presence at group meetings.\n",
    " - Daniel Kong: Title: Contribution. \n",
    " - Joshua Li: Title: Played a role in discussions centered around data preprocessing and exploration. Helped develop a strategy for data cleaning and transformation. Did the writeup for our decision tree analysis. Made edits to the notebook to assist with clarity in the final writeup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb69a02",
   "metadata": {
    "id": "1eb69a02"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
